#+SETUPFILE: setup.org
#+TITLE: Homework 4

* Task 1 (10 pts)

Load the PD N-Person Iterated model in NetLogo. Answer these
questions:

  1. Observe the results of running the model with a variety of
     populations and population sizes. For example, *can you get
     cooperate’s average payoff to be higher than defect’s?* *Can you
     get Tit-for-Tat’s average payoff higher than cooperate’s?* *What
     do these experiments suggest about an optimal strategy?* (2-3
     sentences)

  2. Relate your observations from this model to real life
     events. *Where might you find yourself in a similar situation?
     How might the knowledge obtained from the model influence your
     actions in such a situation? Why?* (3-4 sentences)

* Task 2 (20 pts)

Read/skim "Strong and Weak Emergence" by David Chalmers from 2006
([[./Chalmers-Emergence.pdf][PDF]]; [[http://scholar.google.com/scholar.bib?q=info:j3WRL72mFMkJ:scholar.google.com/&output=citation&hl=en&as_sdt=1,36&scfhb=1&ct=citation&cd=1][full citation]]). Answer these questions:

  1. Chalmers writes, "We can think of strongly emergent phenomena as
     being systematically determined by low-level facts without being
     deducible from those facts." Give an example (1-2 sentences) that
     may possibly satisfy this definition of strong emergence.

  2. Are the NetLogo models we have been using examples of strong or
     weak emergence? Provide a 1-2 sentence argument.

  3. What is the relation between weak emergence, as described by
     Chalmers (second half of the reading) and [[./knowledge-level.html][the knowledge level]]?
     This is a "compare and contrast" type of question. Answer in one
     paragraph (4-5 sentences).


* Task 3 (20 pts)

Execute the k-means algorithm by hand on the following data:

| item # |   w |   x |   y |   z | true label |
|--------+-----+-----+-----+-----+------------|
|      1 | 3.0 | 1.0 | 1.0 | 1.0 | A          |
|      2 | 0.0 | 2.0 | 1.0 | 0.0 | B          |
|      3 | 2.0 | 2.0 | 2.0 | 2.0 | A          |
|      4 | 1.0 | 1.0 | 1.0 | 1.0 | B          |
|      5 | 3.0 | 2.0 | 3.0 | 2.0 | A          |
|      6 | 0.0 | 0.0 | 1.0 | 3.0 | B          |

Use $k=2$. Show the centroids as they change, and give the final
centroids. You must choose random (or not so random) starting centroid
values. Finally, give the confusion matrix.

* Task 4 (10 pts)

Run the k-means algorithm in Weka using this dataset: [[./iris.arff][iris.arff]] (iris
species clustering).

Find the best value of $k$. Give the confusion matrix for this
$k$. Also report the percent of correctly classified instances for
each class.

* Task 5 (20 pts)

Execute the k-nearest neighbor algorithm by hand on the clusters found
from task 1 (or make up random clusters by labeling the points from
task 1). Use $k = 2$. Classify the data point: $<1, 0, 1, 2>$.

* Task 6 (10 pts)

Run the k-nearest neighbor in Weka using this dataset: [[./letter.arff][letter.arff]]
(handwritten letter classification). Find the best value of
$k$. Report the accuracy and give the confusion matrix.

* Task 7 (10 pts)

Explain the differences between k-means and k-nearest neighbor
algorithms. What does each accomplish, and when/why might you use
both?

* Extra credit (20 pts)

Play around with Weka. Report how well at least three different
classification algorithms (avoid k-means and k-nn) perform on the the
[[./letter.arff][letter.arff]] data. Collect accuracies in a table.



#+INCLUDE: footer.org
