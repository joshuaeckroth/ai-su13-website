#+SETUPFILE: setup.org
#+TITLE: Final guide

You can *bring a notecard* (5in x 7in max) with notes or whatnot.

* Multi-agent systems

What are two principles for designing agent-based simulations?

{{{begin-hidden(Answer)}}}
Here are seven:

1. agents not functions (not functional decomposition)
2. keep agents small in size
3. keep agents small in time (forgetful)
4. keep agents small in scope (local sensing and action)
5. decentralizd system control
6. support agent diversity
7. provide an entropy leak
{{{end-hidden}}}

** Prisoner's dilemma

True or false? "Defecting" means confessing to the crime so that you
get off the hook but your partner goes to jail.

{{{begin-hidden(Answer)}}}
True
{{{end-hidden}}}

Describe the "Jesus" strategy.

{{{begin-hidden(Answer)}}}
Always cooperate
{{{end-hidden}}}

Describe the "Lucifer" strategy.

{{{begin-hidden(Answer)}}}
Always defect
{{{end-hidden}}}

Describe the "Unforgiving" strategy.

{{{begin-hidden(Answer)}}}
Cooperate until the partner defects, and then defect forever after.
{{{end-hidden}}}

Describe the "Tit-for-tat" a.k.a. "Moses" strategy. What is the first
choice in this strategy? What are all future choices?

{{{begin-hidden(Answer)}}}
Tit-for-tat does the same action the partner
did in the last time step; it just mirrors the partner. The first
choice (if tit-for-tat goes first) is to cooperate.
{{{end-hidden}}}

Which of these three strategies generally performed best across random
scenarios in the iterated prisoner's dilemma?

{{{begin-hidden(Answer)}}}
Tit-for-tat
{{{end-hidden(Answer)}}}

If two "Tit-for-tat" strategies face each other in the iterated
prisoner's dilemma, we will see behavior equivalent to which
non-Tit-for-tat strategy or strategies facing each other?

{{{begin-hidden(Answer)}}}
Jesus (always-cooperate) strategy
{{{end-hidden}}}

* Learning

Describe the difference between "supervised" and "unsupervised"
learning.

{{{begin-hidden(Answer)}}}

Supervised learning uses information about the truth when
training. Unsupervised learning does not have the truth (ever) so
obviously cannot use this information.

{{{end-hidden}}}

What does "10-fold cross validation" mean?

{{{begin-hidden(Answer)}}}

This happens 10 times, and the results are averaged: Take 90% of the
input data and train the learning algorithm on it; test the learning
algorithm on the remaining 10%. For each of the 10 iterations,
separate the input data into a different 90/10 split.

{{{end-hidden}}}

** k-means clustering

k-means clustering is an unsupervised or supervised learning strategy?

{{{begin-hidden(Answer)}}}
Unsupervised
{{{end-hidden}}}

What does the choice of $k$ represent?

{{{begin-hidden(Answer)}}}
The number of clusters.
{{{end-hidden}}}

How does the choice of initial clusters affect the outcome?

{{{begin-hidden(Answer)}}}

The resulting clusters may be different. Initial clusters near
outliers may result in small clusters around the outliers (which is
usually a bad thing).

{{{end-hidden}}}

** k-nearest neighbor

What does k-nearest neighbor allow us to do with a new, unknown data
point?

{{{begin-hidden(Answer)}}}
Determine its category (class, label, tag, etc.).
{{{end-hidden}}}

k-nearest neighbor is an unsupervised or supervised learning strategy?

{{{begin-hidden(Answer)}}}
Supervised
{{{end-hidden}}}

What does the choice of $k$ represent?

{{{begin-hidden(Answer)}}}

The number of neighbors that get a "vote" during the classification
stage.

{{{end-hidden}}}

What problem may a very small value of $k$ cause?

{{{begin-hidden(Answer)}}}

Noise has too great an impact. The nearest neighbor will be chosen
without considering the "larger" picture.

{{{end-hidden}}}

What problem may a very large value of $k$ cause?

{{{begin-hidden(Answer)}}}

The more common category will be chosen more often than it should.

{{{end-hidden}}}

Is there one value for $k$ that works best for nearly all data sets?
If so, what is it?

{{{begin-hidden(Answer)}}}

There is not one best value; you need to experiment with different
values to find the best for your dataset.

{{{end-hidden}}}

Give one benefit of k-nearest neighbor learning.

{{{begin-hidden(Answer)}}}

It is a very simple algorithm and can work quite well in some cases.

{{{end-hidden}}}

Give one drawback of k-nearest neighbor learning.

{{{begin-hidden(Answer)}}}

It is very slow because it checks every item in the database (unless
KD-trees are used). It also requires one to retain all the training
examples in the database.

{{{end-hidden}}}

** Classification evaluation

Define true positive (TP). Define false positive (FP). Define false
negative (FN). Define precision (in terms of TP and/or FP and/or
FN). Define recall (in terms of TP and/or FP and/or FN). Define
F-score (in terms of precision and/or recall).

{{{begin-hidden(Answer)}}}

- True positive (tp) :: chosen categories that are true categories.

- False positive (fp) :: chosen categories that are not true categories.

- False negatives (fn) :: true categories that are not chosen.

- Precision :: $tp/(tp+fp)$.

- Recall :: $tp/(tp+fn)$.

- F-score :: $2 * precision * recall / (precision + recall)$.

{{{end-hidden}}}

Suppose we make our classification engine more cautious; that is, it
is less likely overall to predict any category. Does precision go up
or down or remain unchanged? Does recall go up or down or remain
unchanged?

{{{begin-hidden(Answer)}}}

Precision goes up because there are fewer $fp$. Recall goes down
because there are more $fn$.

{{{end-hidden}}}

** Probability and Bayesian methods

Describe what $P(a)$ means (in words).

{{{begin-hidden(Answer)}}}

The probability that some event $a$ occurs.

{{{end-hidden}}}

Describe what $P(a,b)$ means (in words).

{{{begin-hidden(Answer)}}}

The probability that two events $A$ and $B$ occur together.

{{{end-hidden}}}

Describe what $P(a|b)$ means (in words).

{{{begin-hidden(Answer)}}}

The probability that some event $a$ occurs given that we know or are
assuming event $b$ also occurs.

{{{end-hidden}}}

If events $a$ and $b$ are independent, and $P(a) = 0.25$, $P(b) =
0.10$, what is $P(a,b)$? What is $P(b,a)$?

{{{begin-hidden(Answer)}}}

$P(a,b) = P(b,a) = 0.25 * 0.10 = 0.025$

{{{end-hidden}}}

In the toothache graph from the [[./bayesian-inference.html][Bayesian inference]] notes (the graph
with just c, g, and t), what is $P(t|g)$?

{{{begin-hidden(Answer)}}}

$$P(t|g) = P(t|g,c)P(c) + P(t|g,\neg c)P(\neg c) = 1.0*0.10 + 0.3*0.9
= 0.37$$

{{{end-hidden}}}

Write Bayes' theorem.

{{{begin-hidden(Answer)}}}

$P(b|a) = P(a|b)P(b)/P(a)$ or equivalently $P(a|b) = P(b|a)P(a)/P(b)$

{{{end-hidden}}}

Using algebra, derive Bayes' theorem from the probability calculus
equalities.

{{{begin-hidden(Answer)}}}

TODO

{{{end-hidden}}}

Suppose I know (or believe) that $P(b|a)=0.1, P(a)=0.9, P(b)=0.25$,
what is $P(a|b)$?

{{{begin-hidden(Answer)}}}

$P(a|b)=0.1*0.9/0.25=0.36$

{{{end-hidden}}}

In the toothache graph from the [[./bayesian-inference.html][Bayesian inference]] notes (the graph
with just c, g, and t), is $P(g|t) > P(c|t)$?

{{{begin-hidden(Answer)}}}

\begin{eqnarray}

P(g|t) = P(t|g)P(g)/P(t) &=& (P(t|g,c)P(c) + P(t|g,\neg c)P(\neg c))P(g)/P(t) \\
 &=& (1.0*0.10 + 0.3*0.9)*0.05/P(t)\\
 &=& 0.0185/P(t) \\

P(c|t) = P(t|c)P(c)/P(t) &=& (P(t|c,g)P(g) + P(t|c,\neg g)P(\neg g))P(c)/P(t) \\
 &=& (1.0*0.05 + 0.6*0.95)*0.10/P(t) \\
 &=& 0.062/P(t)

\end{eqnarray}

So $P(c|t) > P(g|t)$.

{{{end-hidden}}}

What is the outcome of computing $\arg\max X (P(x))$ where $X$ is an
event? (If $\arg\max_x (P(x))$ was a function, what would the output
of the function be?) Describe in English.

{{{begin-hidden(Answer)}}}

The outcome would be an event, not a probability.

{{{end-hidden}}}

Suppose I know (or believe) that $P(b|a)=0.1, P(a)=0.9, P(b|c)=0.2,
P(c)=0.8$, what is $\arg\max_x (P(x|b))$?

{{{begin-hidden(Answer)}}}

The answer is $c$ because $P(b|a)P(a) < P(b|c)P(c)$.

{{{end-hidden}}}

** NaÃ¯ve Bayesian classification

Describe a "binary feature vector" for a text document.

{{{begin-hidden(Answer)}}}

Each unique word is a "dimension," and the value for that dimension is
1 or 0. It is 1 if the word is present in the document, 0 otherwise.

{{{end-hidden}}}



** Neural networks

What does "all or nothing" mean when we talk about neurons in the
brain?

{{{begin-hidden(Answer)}}}

A neuron either fires (discharges) completely or does not fire.

{{{end-hidden}}}

Explain the Hebbian learning rule.

{{{begin-hidden(Answer)}}}

Quotable: "Cells that fire together, wire together." The rule says
that connected neurons that both fire nearby (in time) from some
stimulus, will strengthen their connection. Eventually, if just one or
the other fires, it will induce the second to fire as well.

{{{end-hidden}}}

What is happening when an artificial neural network is "learning"?

{{{begin-hidden(Answer)}}}

The weights on the nodes' inputs are updating.

{{{end-hidden}}}

Generate the input/output table for this perceptron:

#+BEGIN_CENTER
[[./images/arbitrary-perceptron.png]]
#+END_CENTER

{{{begin-hidden(Answer)}}}

| $x_1$ | $x_2$ | output |
|-------+-------+--------|
| 0     | 0     | 0      |
| 0     | 1     | 0      |
| 1     | 0     | 1      |
| 1     | 1     | 0      |

{{{end-hidden}}}

Draw perceptron and define inputs for the NAND function.

{{{begin-hidden(Answer)}}}

#+BEGIN_CENTER
[[./images/nand-perceptron.png]]
#+END_CENTER

{{{end-hidden}}}

Define the word "epoch."

{{{begin-hidden(Answer)}}}

An epoch is a single pass (of weight updates) through every example in
the training set.

{{{end-hidden}}}

Write the perceptron learning rule for a single weight. Define the
variables you use.

{{{begin-hidden(Answer)}}}

$$w'_{ji} = w_{ji} + \alpha (d_j-y_j)x_i,$$

where $w'_{ji}$ is the new weight value, $w_{ji}$ is the old weight
value, $\alpha$ is a "learning rate" parameter, $y_j$ is the binary
value spit out by this perceptron, $d_j$ is the correct value, and
$x_i$ is the input on this weight.

{{{end-hidden}}}

Explain why the perceptron learning rule has $d_j-y_j$ and not
$y_j-d_j$ (everything else being equal).

{{{begin-hidden(Answer)}}}

If $d_j-y_j < 0$, then the predicted value is 1 but the true value is
0; so the predicted value is too high, thus we want to adjust the
weights /down/ so that there is less chance in the future that the
weighted sum will surpass the threshold and produce another 1 output.

If $d_j-y_j > 0$, then the predicted value is 0 but the true value is
1; and we get the opposite effect (adjust weights up so that threshold
might be met in the future).

{{{end-hidden}}}

Give the "loss" function for logistic perceptrons and define the
variables you use.

{{{begin-hidden(Answer)}}}

$$L_j(d_j, p_j) = (d_j - p_j)^2,$$

where $d_j$ is the correct answer (1.0 or 0.0, binary), and
$p_j=f(s_j)$ is the probability from the logistic function. Define
your variables.

{{{end-hidden}}}

Give the logistic perceptron learning rule, with activation function
$1/(1+e^{-s_j})$, where $s_j$ is the weighted sum of a perceptron's
inputs.

{{{begin-hidden(Answer)}}}

$$w'_{ji} = w_{ji} + \alpha (d_j-p_j) p_j (1-p_j)) x_i,$$

where $w'_{ji}$ is the new weight value, $w_{ji}$ is the old weight
value, $\alpha$ is a "learning rate" parameter, $d_j$ is the correct
value, $p_j$ is the predicted value (a probability), and $x_i$ is the
input on this weight.

{{{end-hidden}}}

True or false: a single-layer perceptron network can compute any
function.

{{{begin-hidden(Answer)}}}

False: it can only compute linearly-separable functions, which does
not include, e.g., XOR.

{{{end-hidden}}}

Describe some differences, in terms of processing power and technique,
between a human brain and typical personal computer.

{{{begin-hidden(Answer)}}}

- The brain is highly parallel, but PC's typically process on one or a
  small number of CPUs.

- Each neuron in the brain is slow (several ms per computation), while
  each transistor or processor in a PC is fast (<1 ns per
  computation).

- Information is stored in the brain in a highly distributed fashion;
  information in a PC is highly structured and linear or hierarchical
  (in files and folders).

- Brains are very robust to information loss and corruption (e.g.,
  killing brain cells from boozing); yet just a couple of bit-flips in
  a PC can crash the system.

- Brains change their connectivity over time ("synaptic plasticity");
  PCs never change unless we manually upgrade the hardware. Likewise,
  a brain is a mix of hardware and software, while the two are
  normally quite distinct in a PC.

{{{end-hidden}}}

* Philosophy

** The "Chinese room" argument

What is the essential goal of "strong AI?"

{{{begin-hidden(Answer)}}}

Create a true "mind," i.e., an intelligent thinking machine. It may
even be conscious.

{{{end-hidden}}}

What is the most critical assumption in the Chinese room argument?

{{{begin-hidden(Answer)}}}

That the person in the room does not understand Chinese.

{{{end-hidden}}}

If you believe the Chinese room argument, can you also (reasonably)
believe that passing the Turing test gives proof that a machine
possesses a mind (i.e., can be said to truly understand things)?

{{{begin-hidden(Answer)}}}

No.

{{{end-hidden}}}

** The "Norvig - Chomsky" debate

Give a 2-3 sentence summary of the debate.

{{{begin-hidden(Answer)}}}

Chomsky thinks statistical methods in AI don't lead to any scientific
kinds of insights about intelligence. Norvig says that we have good
reason to believe intelligence is statistical in nature (at least for
some things like hearing words), and besides, the statistical methods
work.

{{{end-hidden}}}

** Robot ethics

Give two ethical issues related to the "take your medicine robot."

{{{begin-hidden(Answer)}}}

Some possible answers:

- Ensure it gives medicine to the right person
- Ensure it gives the right medicine
- Detect responses like "no," no response, etc.
- Define an ethical strategy for responding to "no," to no response,
  etc.
- Figure out if it matters whether or not the robot knows the person
  actually took the medicine
- Ensure reliability of operation
- Keep records private
- Develop a mechanism for updating the robot and changing its
  instructions.
- Define a "hand off of control" mechanism that's possibly more
  complicated than a big red button.

{{{end-hidden}}}


#+INCLUDE: footer.org

